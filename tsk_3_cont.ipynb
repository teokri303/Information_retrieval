{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARXIKA RATINGS:  42708\n",
      "ZERO RATINGS:  13165 \n",
      "\n",
      "Gia to trehon Cluster exoume: \n",
      "Non zero ratings tou cluster:  6835\n",
      "Zero ratings tou cluster:  2079\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis:  11086 \n",
      "\n",
      "Gia to trehon Cluster exoume: \n",
      "Non zero ratings tou cluster:  9812\n",
      "Zero ratings tou cluster:  3160\n",
      "99/99 [==============================] - 0s 1ms/step\n",
      "OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis:  7926 \n",
      "\n",
      "Gia to trehon Cluster exoume: \n",
      "Non zero ratings tou cluster:  264\n",
      "Zero ratings tou cluster:  97\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis:  7831 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# pairnoume ta aparaitita arxeia \n",
    "data = pd.read_csv('Updated-Ratings.csv')\n",
    "books = pd.read_csv('BX-Books.csv')\n",
    "clust_1 = pd.read_csv('Clust_1.csv')\n",
    "clust_2 = pd.read_csv('Clust_2.csv')\n",
    "clust_3 = pd.read_csv('Clust_3.csv')\n",
    "\n",
    "zero_ratings = data[data['rating'] == 0]\n",
    "\n",
    "print('ARXIKA RATINGS: ', len(data))\n",
    "print('ZERO RATINGS: ', len(zero_ratings), '\\n')\n",
    "\n",
    "c1_uids = list(set(clust_1.uid).intersection(set(data.uid)))\n",
    "c2_uids = list(set(clust_2.uid).intersection(set(data.uid)))\n",
    "c3_uids = list(set(clust_3.uid).intersection(set(data.uid)))\n",
    "\n",
    "\n",
    "# diaxorizoume ta ratings pou exoume analoga me to cluster twn users pou tis ekanan\n",
    "c1_ratings = data[data.uid.isin(c1_uids)]\n",
    "c2_ratings = data[data.uid.isin(c2_uids)]\n",
    "c3_ratings = data[data.uid.isin(c3_uids)]\n",
    "\n",
    "#print(len(c1_ratings))\n",
    "#print(len(c2_ratings))\n",
    "#print(len(c3_ratings))\n",
    "\n",
    "# apo edw argotera tha to automatopoihsoyme gia na ginetai mia fora gia ola.\n",
    "clusters = [c1_ratings, c2_ratings, c3_ratings]\n",
    "\n",
    "for cluster in clusters:\n",
    "    # diaxwrizoume tis vathmologies tou kathe cluster se zero kai non_zero\n",
    "    zero_ratings_clust = cluster[cluster['rating'] == 0]\n",
    "    non_zero_ratings_clust = cluster[cluster['rating'] != 0]\n",
    "\n",
    "    # prosthetoume sta dedomena ta summaries gia to kathe vivlio poy exei vathmologithei sto cluster\n",
    "    sum1_non_zero = pd.merge(non_zero_ratings_clust, books, how='inner', on='isbn')\n",
    "    sum1_zero = pd.merge(zero_ratings_clust, books, how='inner', on='isbn')\n",
    "\n",
    "    # ksexwriszoume ta summaries se listes wste na einai etoima gia to vectorization\n",
    "    sums = sum1_non_zero.summary.values.tolist()\n",
    "    zero_sums = sum1_zero.summary.values.tolist()\n",
    "\n",
    "    #makings vectors\n",
    "    # gia ta non zero summaries pou tha einai to X_train\n",
    "    print('Gia to trehon Cluster exoume: ' )\n",
    "\n",
    "    model_vect = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    X_train = model_vect.encode(sums)\n",
    "    print('Non zero ratings tou cluster: ', len(X_train))\n",
    "\n",
    "    # oi vathmologies twn non zero books pou tha perasoun sto model mazi me ta summaries\n",
    "    y_train = sum1_non_zero.rating.values.tolist()\n",
    "\n",
    "    # gia ta zero summaries pou tha einai to X_test\n",
    "    model_vect = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    X_test = model_vect.encode(zero_sums)\n",
    "    print('Zero ratings tou cluster: ', len(X_test))\n",
    "\n",
    "    # metatroph se np arrays giati allios den mporoun na mpoun sto keras model\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    #creating layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(384, input_shape = (384,)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(192, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(96, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "    # model compile apairaitito prin tin xrhsh tou model \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # etoimasia twn ratings gia eisagwgh\n",
    "    y_pred = np.array(y_pred)\n",
    "    values = y_pred.flatten()\n",
    "    values = np.round(values, 0)\n",
    "\n",
    "    zero_ratings_clust['rating'] = values\n",
    "\n",
    "\n",
    "    # eidagwgh twn provlepsewn sta arxika ratings kai antikatastash twn 0 \n",
    "    data.update(zero_ratings_clust)\n",
    "\n",
    "    zero_ratings = data[data['rating'] == 0]\n",
    "    print('OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis: ' , len(zero_ratings), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0       uid        isbn  rating\n",
      "0             0.0  123629.0  0002005018     9.0\n",
      "1             1.0  198013.0  0399135782     7.0\n",
      "2             2.0  212449.0  0399135782     8.0\n",
      "3             3.0  252921.0  0399135782     8.0\n",
      "4             4.0   12923.0  0440234743    10.0\n",
      "...           ...       ...         ...     ...\n",
      "42703     42703.0  277831.0  0786811358     5.0\n",
      "42704     42704.0  277834.0  0847817741     7.0\n",
      "42705     42705.0  278714.0  0896101932     0.0\n",
      "42706     42706.0  278789.0  1413702783     9.0\n",
      "42707     42707.0  278849.0  0920656307     6.0\n",
      "\n",
      "[42708 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
