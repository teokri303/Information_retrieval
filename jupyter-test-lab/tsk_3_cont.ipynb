{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-14 19:56:01.918245: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARXIKA RATINGS:  22247\n",
      "ZERO RATINGS:  5336 \n",
      "\n",
      "Gia to trehon Cluster exoume: \n",
      "Non zero ratings tou cluster:  6835\n",
      "Zero ratings tou cluster:  2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 19:57:46.811548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step\n",
      "OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis:  3257 \n",
      "\n",
      "Gia to trehon Cluster exoume: \n",
      "Non zero ratings tou cluster:  9812\n",
      "Zero ratings tou cluster:  3160\n",
      "99/99 [==============================] - 0s 1ms/step\n",
      "OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis:  97 \n",
      "\n",
      "Gia to trehon Cluster exoume: \n",
      "Non zero ratings tou cluster:  264\n",
      "Zero ratings tou cluster:  97\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis:  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# pairnoume ta aparaitita arxeia \n",
    "data = pd.read_csv('../Updated-Ratings.csv')\n",
    "books = pd.read_csv('../BX-Books.csv')\n",
    "clust_1 = pd.read_csv('../data/Clust_1.csv')\n",
    "clust_2 = pd.read_csv('../data/Clust_2.csv')\n",
    "clust_3 = pd.read_csv('../data/Clust_3.csv')\n",
    "\n",
    "zero_ratings = data[data['rating'] == 0]\n",
    "\n",
    "print('ARXIKA RATINGS: ', len(data))\n",
    "print('ZERO RATINGS: ', len(zero_ratings), '\\n')\n",
    "\n",
    "c1_uids = list(set(clust_1.uid).intersection(set(data.uid)))\n",
    "c2_uids = list(set(clust_2.uid).intersection(set(data.uid)))\n",
    "c3_uids = list(set(clust_3.uid).intersection(set(data.uid)))\n",
    "\n",
    "\n",
    "# diaxorizoume ta ratings pou exoume analoga me to cluster twn users pou tis ekanan\n",
    "c1_ratings = data[data.uid.isin(c1_uids)]\n",
    "c2_ratings = data[data.uid.isin(c2_uids)]\n",
    "c3_ratings = data[data.uid.isin(c3_uids)]\n",
    "\n",
    "#print(len(c1_ratings))\n",
    "#print(len(c2_ratings))\n",
    "#print(len(c3_ratings))\n",
    "\n",
    "# apo edw argotera tha to automatopoihsoyme gia na ginetai mia fora gia ola.\n",
    "clusters = [c1_ratings, c2_ratings, c3_ratings]\n",
    "\n",
    "for cluster in clusters:\n",
    "    # diaxwrizoume tis vathmologies tou kathe cluster se zero kai non_zero\n",
    "    zero_ratings_clust = cluster[cluster['rating'] == 0]\n",
    "    non_zero_ratings_clust = cluster[cluster['rating'] != 0]\n",
    "\n",
    "    # prosthetoume sta dedomena ta summaries gia to kathe vivlio poy exei vathmologithei sto cluster\n",
    "    sum1_non_zero = pd.merge(non_zero_ratings_clust, books, how='inner', on='isbn')\n",
    "    sum1_zero = pd.merge(zero_ratings_clust, books, how='inner', on='isbn')\n",
    "\n",
    "    # ksexwriszoume ta summaries se listes wste na einai etoima gia to vectorization\n",
    "    sums = sum1_non_zero.summary.values.tolist()\n",
    "    zero_sums = sum1_zero.summary.values.tolist()\n",
    "\n",
    "    #makings vectors\n",
    "    # gia ta non zero summaries pou tha einai to X_train\n",
    "    print('Gia to trehon Cluster exoume: ' )\n",
    "\n",
    "    model_vect = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    X_train = model_vect.encode(sums)\n",
    "    print('Non zero ratings tou cluster: ', len(X_train))\n",
    "\n",
    "    # oi vathmologies twn non zero books pou tha perasoun sto model mazi me ta summaries\n",
    "    y_train = sum1_non_zero.rating.values.tolist()\n",
    "\n",
    "    # gia ta zero summaries pou tha einai to X_test\n",
    "    model_vect = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    X_test = model_vect.encode(zero_sums)\n",
    "    print('Zero ratings tou cluster: ', len(X_test))\n",
    "\n",
    "    # metatroph se np arrays giati allios den mporoun na mpoun sto keras model\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    #creating layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(384, input_shape = (384,)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(192, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(96, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "    # model compile apairaitito prin tin xrhsh tou model \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # etoimasia twn ratings gia eisagwgh\n",
    "    y_pred = np.array(y_pred)\n",
    "    values = y_pred.flatten()\n",
    "    values = np.round(values, 0)\n",
    "\n",
    "    zero_ratings_clust['rating'] = values\n",
    "\n",
    "\n",
    "    # eidagwgh twn provlepsewn sta arxika ratings kai antikatastash twn 0 \n",
    "    data.update(zero_ratings_clust)\n",
    "\n",
    "    zero_ratings = data[data['rating'] == 0]\n",
    "    print('OLA TA ZERO RATINGS meta tin prosthiki tis provlepsis: ' , len(zero_ratings), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0       uid        isbn  rating\n",
      "0             0.0  252921.0  0399135782     8.0\n",
      "1             1.0   12923.0  0440234743    10.0\n",
      "2             2.0   21264.0  0440234743     5.0\n",
      "3             3.0   31299.0  0440234743    10.0\n",
      "4             4.0  131681.0  0440234743     9.0\n",
      "...           ...       ...         ...     ...\n",
      "22242     22242.0  277528.0  0974499005     3.0\n",
      "22243     22243.0  277831.0  0786811358     5.0\n",
      "22244     22244.0  277834.0  0847817741     5.0\n",
      "22245     22245.0  278789.0  1413702783     8.0\n",
      "22246     22246.0  278849.0  0920656307     5.0\n",
      "\n",
      "[22247 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural ratings is saved. \n"
     ]
    }
   ],
   "source": [
    "#data.to_csv('Neural-Final-Updated-Ratings.csv')\n",
    "print(\"Neural ratings is saved. \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
